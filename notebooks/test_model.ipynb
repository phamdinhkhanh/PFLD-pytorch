{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Input channel: 160. Output channel: 16\nAfter remaiing blocks:  torch.Size([1, 16, 8, 8])\n"
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Given input size: (16x8x8). Calculated output size: (16x0x0). Output size is too small",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-866af4a1db61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m112\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m \u001b[0mfea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;31m# print(\"Time: \", time.time()-t1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;31m# print(\"Shape fea: \", fea.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/entrance/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-86-866af4a1db61>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After remaiing blocks: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/entrance/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/entrance/lib/python3.7/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         return F.avg_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m--> 554\u001b[0;31m                             self.padding, self.ceil_mode, self.count_include_pad, self.divisor_override)\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (16x8x8). Calculated output size: (16x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../models\")\n",
    "from pfld import InvertedResidual\n",
    "from ghostnet import GhostBottleneck, GhostModule, GhostNet, ghostnet, _make_divisible, ConvBnAct\n",
    "from pfld import PFLDInference, conv_bn\n",
    "import torch\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "cfgs = [\n",
    "        # k, t, c, SE, s \n",
    "        # stage1\n",
    "        [[3,  16,  16, 0, 2]],\n",
    "        # stage2\n",
    "        [[3,  48,  24, 0, 1]],\n",
    "        [[3,  72,  24, 0, 1]],\n",
    "        # stage3\n",
    "        [[5,  72,  40, 0.25, 1]],\n",
    "        [[5, 120,  40, 0.25, 1]],\n",
    "        # stage4\n",
    "        [[3, 240,  64, 0, 1]], #The original number of channels here is 80, but I change to 64 so that it fit to the AuxiliaryNet\n",
    "        [[3, 200,  80, 0, 2],\n",
    "         [3, 184,  80, 0, 1],\n",
    "         [3, 184,  80, 0, 1],\n",
    "         [3, 480, 112, 0.25, 1],\n",
    "         [3, 672, 112, 0.25, 1]\n",
    "        ],\n",
    "        # stage5\n",
    "        [[5, 672, 160, 0.25, 1]],\n",
    "        [[5, 960, 160, 0, 1],\n",
    "         [5, 960, 160, 0.25, 1],\n",
    "         [5, 960, 160, 0, 1],\n",
    "         [5, 960, 160, 0.25, 1]\n",
    "        ],\n",
    "\n",
    "        # final\n",
    "        # [[5, 320, 16, 0.25, 1]]\n",
    "    ]\n",
    "\n",
    "class CustomizedGhostNet(nn.Module):\n",
    "    def __init__(self, cfgs, width=1.0, dropout=0.2):\n",
    "        super(CustomizedGhostNet, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = cfgs\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # building first layer\n",
    "        output_channel = _make_divisible(16 * width, 4)\n",
    "        self.conv_stem = nn.Conv2d(3, output_channel, 3, 2, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(output_channel)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        input_channel = output_channel\n",
    "\n",
    "        # building inverted residual blocks\n",
    "        first_6_stages = []  # This one used for another branch\n",
    "        remaining_stages = []\n",
    "        stages = []\n",
    "        block = GhostBottleneck\n",
    "        for i, cfg in enumerate(self.cfgs):\n",
    "            layers = []\n",
    "            for k, exp_size, c, se_ratio, s in cfg:\n",
    "                output_channel = _make_divisible(c * width, 4)\n",
    "                hidden_channel = _make_divisible(exp_size * width, 4)\n",
    "                layers.append(block(input_channel, hidden_channel, output_channel, k, s,\n",
    "                            se_ratio=se_ratio))\n",
    "                input_channel = output_channel\n",
    "\n",
    "            if i<=5:\n",
    "                first_6_stages.append(nn.Sequential(*layers))\n",
    "            else:\n",
    "                remaining_stages.append(nn.Sequential(*layers))\n",
    "                \n",
    "\n",
    "        # output_channel = _make_divisible(c * width, 4)\n",
    "        output_channel = 16\n",
    "        print(f\"Input channel: {input_channel}. Output channel: {output_channel}\")\n",
    "        remaining_stages.append(nn.Sequential(ConvBnAct(input_channel, output_channel, 1)))\n",
    "        \n",
    "        self.begining_blocks = nn.Sequential(*first_6_stages)\n",
    "        self.remaining_blocks = nn.Sequential(*remaining_stages)  # 16x14x14\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv7 = conv_bn(16, 32, 3, 2)  # [32, 7, 7]\n",
    "        self.conv8 = nn.Conv2d(32, 128, 7, 1, 0)  # [128, 1, 1]\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "\n",
    "        self.avg_pool1 = nn.AvgPool2d(14)\n",
    "        self.avg_pool2 = nn.AvgPool2d(7)\n",
    "        self.fc = nn.Linear(176, 196)\n",
    "\n",
    "        # building last several layers\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stem(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        features_for_auxiliarynet = self.begining_blocks(x)\n",
    "        x = self.remaining_blocks(features_for_auxiliarynet)\n",
    "        print(\"After remaiing blocks: \", x.shape)\n",
    "\n",
    "        x1 = self.avg_pool1(x)\n",
    "        x1 = x1.view(x1.size(0), -1)\n",
    "\n",
    "        x = self.conv7(x)\n",
    "        x2 = self.avg_pool2(x)\n",
    "\n",
    "        x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "        x3 = self.relu(self.conv8(x))\n",
    "\n",
    "        x3 = x3.view(x1.size(0), -1)\n",
    "\n",
    "        multi_scale = torch.cat([x1, x2, x3], 1)\n",
    "        landmarks = self.fc(multi_scale)\n",
    "    \n",
    "        return features_for_auxiliarynet, landmarks\n",
    "\n",
    "\n",
    "model = CustomizedGhostNet(cfgs, width=1)\n",
    "model.eval()\n",
    "input = torch.randn(1,3,112,112)\n",
    "t1 = time.time()\n",
    "fea, x = model(input)\n",
    "# print(\"Time: \", time.time()-t1)\n",
    "# print(\"Shape fea: \", fea.shape)\n",
    "# print(\"Remainig X: \", x.shape)\n",
    "\n",
    "len(model.state_dict().keys())\n",
    "b = list(model.state_dict().keys())\n",
    "\n",
    "# b1 = list(filter(lambda i: \"ghost\" in i , b))\n",
    "# len(b1)\n",
    "for c,i in enumerate(b):\n",
    "  print(i)\n",
    "  if c >=510:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([8, 16, 1, 1])"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "model.state_dict()[\"begining_blocks.0.0.ghost1.primary_conv.0.weight\"].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([8, 16, 1, 1])"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "ck[\"blocks.0.0.ghost1.primary_conv.0.weight\"].data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.state_dict()[\"begining_blocks.0.0.ghost1.primary_conv.0.weight\"].data.copy_(ck[\"blocks.0.0.ghost1.primary_conv.0.weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 23.3455, 139.7292,  44.6235,  26.9664,  18.4615, 183.8672,  36.9102,\n        184.1216,   9.0285,  28.0025,  16.6433, 125.6434,   8.6564,  40.1010,\n         25.9697,   7.4062])"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "ck[\"blocks.1.0.shortcut.1.running_var\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nblocks.0.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.1.0.ghost1.primary_conv.0.weight\nblocks.1.0.ghost1.primary_conv.1.weight\nblocks.1.0.ghost1.primary_conv.1.bias\nblocks.1.0.ghost1.primary_conv.1.running_mean\nblocks.1.0.ghost1.primary_conv.1.running_var\nblocks.1.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.1.0.ghost1.cheap_operation.0.weight\nblocks.1.0.ghost1.cheap_operation.1.weight\nblocks.1.0.ghost1.cheap_operation.1.bias\nblocks.1.0.ghost1.cheap_operation.1.running_mean\nblocks.1.0.ghost1.cheap_operation.1.running_var\nblocks.1.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.1.0.conv_dw.weight\nblocks.1.0.bn_dw.weight\nblocks.1.0.bn_dw.bias\nblocks.1.0.bn_dw.running_mean\nblocks.1.0.bn_dw.running_var\nblocks.1.0.bn_dw.num_batches_tracked\nblocks.1.0.ghost2.primary_conv.0.weight\nblocks.1.0.ghost2.primary_conv.1.weight\nblocks.1.0.ghost2.primary_conv.1.bias\nblocks.1.0.ghost2.primary_conv.1.running_mean\nblocks.1.0.ghost2.primary_conv.1.running_var\nblocks.1.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.1.0.ghost2.cheap_operation.0.weight\nblocks.1.0.ghost2.cheap_operation.1.weight\nblocks.1.0.ghost2.cheap_operation.1.bias\nblocks.1.0.ghost2.cheap_operation.1.running_mean\nblocks.1.0.ghost2.cheap_operation.1.running_var\nblocks.1.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.1.0.shortcut.0.weight\nblocks.1.0.shortcut.1.weight\nblocks.1.0.shortcut.1.bias\nblocks.1.0.shortcut.1.running_mean\nblocks.1.0.shortcut.1.running_var\nblocks.1.0.shortcut.1.num_batches_tracked\nblocks.1.0.shortcut.2.weight\nblocks.1.0.shortcut.3.weight\nblocks.1.0.shortcut.3.bias\nblocks.1.0.shortcut.3.running_mean\nblocks.1.0.shortcut.3.running_var\nblocks.1.0.shortcut.3.num_batches_tracked\nblocks.2.0.ghost1.primary_conv.0.weight\nblocks.2.0.ghost1.primary_conv.1.weight\nblocks.2.0.ghost1.primary_conv.1.bias\nblocks.2.0.ghost1.primary_conv.1.running_mean\nblocks.2.0.ghost1.primary_conv.1.running_var\nblocks.2.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.2.0.ghost1.cheap_operation.0.weight\nblocks.2.0.ghost1.cheap_operation.1.weight\nblocks.2.0.ghost1.cheap_operation.1.bias\nblocks.2.0.ghost1.cheap_operation.1.running_mean\nblocks.2.0.ghost1.cheap_operation.1.running_var\nblocks.2.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.2.0.ghost2.primary_conv.0.weight\nblocks.2.0.ghost2.primary_conv.1.weight\nblocks.2.0.ghost2.primary_conv.1.bias\nblocks.2.0.ghost2.primary_conv.1.running_mean\nblocks.2.0.ghost2.primary_conv.1.running_var\nblocks.2.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.2.0.ghost2.cheap_operation.0.weight\nblocks.2.0.ghost2.cheap_operation.1.weight\nblocks.2.0.ghost2.cheap_operation.1.bias\nblocks.2.0.ghost2.cheap_operation.1.running_mean\nblocks.2.0.ghost2.cheap_operation.1.running_var\nblocks.2.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.3.0.ghost1.primary_conv.0.weight\nblocks.3.0.ghost1.primary_conv.1.weight\nblocks.3.0.ghost1.primary_conv.1.bias\nblocks.3.0.ghost1.primary_conv.1.running_mean\nblocks.3.0.ghost1.primary_conv.1.running_var\nblocks.3.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.3.0.ghost1.cheap_operation.0.weight\nblocks.3.0.ghost1.cheap_operation.1.weight\nblocks.3.0.ghost1.cheap_operation.1.bias\nblocks.3.0.ghost1.cheap_operation.1.running_mean\nblocks.3.0.ghost1.cheap_operation.1.running_var\nblocks.3.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.3.0.conv_dw.weight\nblocks.3.0.bn_dw.weight\nblocks.3.0.bn_dw.bias\nblocks.3.0.bn_dw.running_mean\nblocks.3.0.bn_dw.running_var\nblocks.3.0.bn_dw.num_batches_tracked\nblocks.3.0.se.conv_reduce.weight\nblocks.3.0.se.conv_reduce.bias\nblocks.3.0.se.conv_expand.weight\nblocks.3.0.se.conv_expand.bias\nblocks.3.0.ghost2.primary_conv.0.weight\nblocks.3.0.ghost2.primary_conv.1.weight\nblocks.3.0.ghost2.primary_conv.1.bias\nblocks.3.0.ghost2.primary_conv.1.running_mean\nblocks.3.0.ghost2.primary_conv.1.running_var\nblocks.3.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.3.0.ghost2.cheap_operation.0.weight\nblocks.3.0.ghost2.cheap_operation.1.weight\nblocks.3.0.ghost2.cheap_operation.1.bias\nblocks.3.0.ghost2.cheap_operation.1.running_mean\nblocks.3.0.ghost2.cheap_operation.1.running_var\nblocks.3.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.3.0.shortcut.0.weight\nblocks.3.0.shortcut.1.weight\nblocks.3.0.shortcut.1.bias\nblocks.3.0.shortcut.1.running_mean\nblocks.3.0.shortcut.1.running_var\nblocks.3.0.shortcut.1.num_batches_tracked\nblocks.3.0.shortcut.2.weight\nblocks.3.0.shortcut.3.weight\nblocks.3.0.shortcut.3.bias\nblocks.3.0.shortcut.3.running_mean\nblocks.3.0.shortcut.3.running_var\nblocks.3.0.shortcut.3.num_batches_tracked\nblocks.4.0.ghost1.primary_conv.0.weight\nblocks.4.0.ghost1.primary_conv.1.weight\nblocks.4.0.ghost1.primary_conv.1.bias\nblocks.4.0.ghost1.primary_conv.1.running_mean\nblocks.4.0.ghost1.primary_conv.1.running_var\nblocks.4.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.4.0.ghost1.cheap_operation.0.weight\nblocks.4.0.ghost1.cheap_operation.1.weight\nblocks.4.0.ghost1.cheap_operation.1.bias\nblocks.4.0.ghost1.cheap_operation.1.running_mean\nblocks.4.0.ghost1.cheap_operation.1.running_var\nblocks.4.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.4.0.se.conv_reduce.weight\nblocks.4.0.se.conv_reduce.bias\nblocks.4.0.se.conv_expand.weight\nblocks.4.0.se.conv_expand.bias\nblocks.4.0.ghost2.primary_conv.0.weight\nblocks.4.0.ghost2.primary_conv.1.weight\nblocks.4.0.ghost2.primary_conv.1.bias\nblocks.4.0.ghost2.primary_conv.1.running_mean\nblocks.4.0.ghost2.primary_conv.1.running_var\nblocks.4.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.4.0.ghost2.cheap_operation.0.weight\nblocks.4.0.ghost2.cheap_operation.1.weight\nblocks.4.0.ghost2.cheap_operation.1.bias\nblocks.4.0.ghost2.cheap_operation.1.running_mean\nblocks.4.0.ghost2.cheap_operation.1.running_var\nblocks.4.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.5.0.ghost1.primary_conv.0.weight\nblocks.5.0.ghost1.primary_conv.1.weight\nblocks.5.0.ghost1.primary_conv.1.bias\nblocks.5.0.ghost1.primary_conv.1.running_mean\nblocks.5.0.ghost1.primary_conv.1.running_var\nblocks.5.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.5.0.ghost1.cheap_operation.0.weight\nblocks.5.0.ghost1.cheap_operation.1.weight\nblocks.5.0.ghost1.cheap_operation.1.bias\nblocks.5.0.ghost1.cheap_operation.1.running_mean\nblocks.5.0.ghost1.cheap_operation.1.running_var\nblocks.5.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.5.0.conv_dw.weight\nblocks.5.0.bn_dw.weight\nblocks.5.0.bn_dw.bias\nblocks.5.0.bn_dw.running_mean\nblocks.5.0.bn_dw.running_var\nblocks.5.0.bn_dw.num_batches_tracked\nblocks.5.0.ghost2.primary_conv.0.weight\nblocks.5.0.ghost2.primary_conv.1.weight\nblocks.5.0.ghost2.primary_conv.1.bias\nblocks.5.0.ghost2.primary_conv.1.running_mean\nblocks.5.0.ghost2.primary_conv.1.running_var\nblocks.5.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.5.0.ghost2.cheap_operation.0.weight\nblocks.5.0.ghost2.cheap_operation.1.weight\nblocks.5.0.ghost2.cheap_operation.1.bias\nblocks.5.0.ghost2.cheap_operation.1.running_mean\nblocks.5.0.ghost2.cheap_operation.1.running_var\nblocks.5.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.5.0.shortcut.0.weight\nblocks.5.0.shortcut.1.weight\nblocks.5.0.shortcut.1.bias\nblocks.5.0.shortcut.1.running_mean\nblocks.5.0.shortcut.1.running_var\nblocks.5.0.shortcut.1.num_batches_tracked\nblocks.5.0.shortcut.2.weight\nblocks.5.0.shortcut.3.weight\nblocks.5.0.shortcut.3.bias\nblocks.5.0.shortcut.3.running_mean\nblocks.5.0.shortcut.3.running_var\nblocks.5.0.shortcut.3.num_batches_tracked\nblocks.6.0.ghost1.primary_conv.0.weight\nblocks.6.0.ghost1.primary_conv.1.weight\nblocks.6.0.ghost1.primary_conv.1.bias\nblocks.6.0.ghost1.primary_conv.1.running_mean\nblocks.6.0.ghost1.primary_conv.1.running_var\nblocks.6.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.6.0.ghost1.cheap_operation.0.weight\nblocks.6.0.ghost1.cheap_operation.1.weight\nblocks.6.0.ghost1.cheap_operation.1.bias\nblocks.6.0.ghost1.cheap_operation.1.running_mean\nblocks.6.0.ghost1.cheap_operation.1.running_var\nblocks.6.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.6.0.ghost2.primary_conv.0.weight\nblocks.6.0.ghost2.primary_conv.1.weight\nblocks.6.0.ghost2.primary_conv.1.bias\nblocks.6.0.ghost2.primary_conv.1.running_mean\nblocks.6.0.ghost2.primary_conv.1.running_var\nblocks.6.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.6.0.ghost2.cheap_operation.0.weight\nblocks.6.0.ghost2.cheap_operation.1.weight\nblocks.6.0.ghost2.cheap_operation.1.bias\nblocks.6.0.ghost2.cheap_operation.1.running_mean\nblocks.6.0.ghost2.cheap_operation.1.running_var\nblocks.6.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.6.1.ghost1.primary_conv.0.weight\nblocks.6.1.ghost1.primary_conv.1.weight\nblocks.6.1.ghost1.primary_conv.1.bias\nblocks.6.1.ghost1.primary_conv.1.running_mean\nblocks.6.1.ghost1.primary_conv.1.running_var\nblocks.6.1.ghost1.primary_conv.1.num_batches_tracked\nblocks.6.1.ghost1.cheap_operation.0.weight\nblocks.6.1.ghost1.cheap_operation.1.weight\nblocks.6.1.ghost1.cheap_operation.1.bias\nblocks.6.1.ghost1.cheap_operation.1.running_mean\nblocks.6.1.ghost1.cheap_operation.1.running_var\nblocks.6.1.ghost1.cheap_operation.1.num_batches_tracked\nblocks.6.1.ghost2.primary_conv.0.weight\nblocks.6.1.ghost2.primary_conv.1.weight\nblocks.6.1.ghost2.primary_conv.1.bias\nblocks.6.1.ghost2.primary_conv.1.running_mean\nblocks.6.1.ghost2.primary_conv.1.running_var\nblocks.6.1.ghost2.primary_conv.1.num_batches_tracked\nblocks.6.1.ghost2.cheap_operation.0.weight\nblocks.6.1.ghost2.cheap_operation.1.weight\nblocks.6.1.ghost2.cheap_operation.1.bias\nblocks.6.1.ghost2.cheap_operation.1.running_mean\nblocks.6.1.ghost2.cheap_operation.1.running_var\nblocks.6.1.ghost2.cheap_operation.1.num_batches_tracked\nblocks.6.2.ghost1.primary_conv.0.weight\nblocks.6.2.ghost1.primary_conv.1.weight\nblocks.6.2.ghost1.primary_conv.1.bias\nblocks.6.2.ghost1.primary_conv.1.running_mean\nblocks.6.2.ghost1.primary_conv.1.running_var\nblocks.6.2.ghost1.primary_conv.1.num_batches_tracked\nblocks.6.2.ghost1.cheap_operation.0.weight\nblocks.6.2.ghost1.cheap_operation.1.weight\nblocks.6.2.ghost1.cheap_operation.1.bias\nblocks.6.2.ghost1.cheap_operation.1.running_mean\nblocks.6.2.ghost1.cheap_operation.1.running_var\nblocks.6.2.ghost1.cheap_operation.1.num_batches_tracked\nblocks.6.2.ghost2.primary_conv.0.weight\nblocks.6.2.ghost2.primary_conv.1.weight\nblocks.6.2.ghost2.primary_conv.1.bias\nblocks.6.2.ghost2.primary_conv.1.running_mean\nblocks.6.2.ghost2.primary_conv.1.running_var\nblocks.6.2.ghost2.primary_conv.1.num_batches_tracked\nblocks.6.2.ghost2.cheap_operation.0.weight\nblocks.6.2.ghost2.cheap_operation.1.weight\nblocks.6.2.ghost2.cheap_operation.1.bias\nblocks.6.2.ghost2.cheap_operation.1.running_mean\nblocks.6.2.ghost2.cheap_operation.1.running_var\nblocks.6.2.ghost2.cheap_operation.1.num_batches_tracked\nblocks.6.3.ghost1.primary_conv.0.weight\nblocks.6.3.ghost1.primary_conv.1.weight\nblocks.6.3.ghost1.primary_conv.1.bias\nblocks.6.3.ghost1.primary_conv.1.running_mean\nblocks.6.3.ghost1.primary_conv.1.running_var\nblocks.6.3.ghost1.primary_conv.1.num_batches_tracked\nblocks.6.3.ghost1.cheap_operation.0.weight\nblocks.6.3.ghost1.cheap_operation.1.weight\nblocks.6.3.ghost1.cheap_operation.1.bias\nblocks.6.3.ghost1.cheap_operation.1.running_mean\nblocks.6.3.ghost1.cheap_operation.1.running_var\nblocks.6.3.ghost1.cheap_operation.1.num_batches_tracked\nblocks.6.3.se.conv_reduce.weight\nblocks.6.3.se.conv_reduce.bias\nblocks.6.3.se.conv_expand.weight\nblocks.6.3.se.conv_expand.bias\nblocks.6.3.ghost2.primary_conv.0.weight\nblocks.6.3.ghost2.primary_conv.1.weight\nblocks.6.3.ghost2.primary_conv.1.bias\nblocks.6.3.ghost2.primary_conv.1.running_mean\nblocks.6.3.ghost2.primary_conv.1.running_var\nblocks.6.3.ghost2.primary_conv.1.num_batches_tracked\nblocks.6.3.ghost2.cheap_operation.0.weight\nblocks.6.3.ghost2.cheap_operation.1.weight\nblocks.6.3.ghost2.cheap_operation.1.bias\nblocks.6.3.ghost2.cheap_operation.1.running_mean\nblocks.6.3.ghost2.cheap_operation.1.running_var\nblocks.6.3.ghost2.cheap_operation.1.num_batches_tracked\nblocks.6.3.shortcut.0.weight\nblocks.6.3.shortcut.1.weight\nblocks.6.3.shortcut.1.bias\nblocks.6.3.shortcut.1.running_mean\nblocks.6.3.shortcut.1.running_var\nblocks.6.3.shortcut.1.num_batches_tracked\nblocks.6.3.shortcut.2.weight\nblocks.6.3.shortcut.3.weight\nblocks.6.3.shortcut.3.bias\nblocks.6.3.shortcut.3.running_mean\nblocks.6.3.shortcut.3.running_var\nblocks.6.3.shortcut.3.num_batches_tracked\nblocks.6.4.ghost1.primary_conv.0.weight\nblocks.6.4.ghost1.primary_conv.1.weight\nblocks.6.4.ghost1.primary_conv.1.bias\nblocks.6.4.ghost1.primary_conv.1.running_mean\nblocks.6.4.ghost1.primary_conv.1.running_var\nblocks.6.4.ghost1.primary_conv.1.num_batches_tracked\nblocks.6.4.ghost1.cheap_operation.0.weight\nblocks.6.4.ghost1.cheap_operation.1.weight\nblocks.6.4.ghost1.cheap_operation.1.bias\nblocks.6.4.ghost1.cheap_operation.1.running_mean\nblocks.6.4.ghost1.cheap_operation.1.running_var\nblocks.6.4.ghost1.cheap_operation.1.num_batches_tracked\nblocks.6.4.se.conv_reduce.weight\nblocks.6.4.se.conv_reduce.bias\nblocks.6.4.se.conv_expand.weight\nblocks.6.4.se.conv_expand.bias\nblocks.6.4.ghost2.primary_conv.0.weight\nblocks.6.4.ghost2.primary_conv.1.weight\nblocks.6.4.ghost2.primary_conv.1.bias\nblocks.6.4.ghost2.primary_conv.1.running_mean\nblocks.6.4.ghost2.primary_conv.1.running_var\nblocks.6.4.ghost2.primary_conv.1.num_batches_tracked\nblocks.6.4.ghost2.cheap_operation.0.weight\nblocks.6.4.ghost2.cheap_operation.1.weight\nblocks.6.4.ghost2.cheap_operation.1.bias\nblocks.6.4.ghost2.cheap_operation.1.running_mean\nblocks.6.4.ghost2.cheap_operation.1.running_var\nblocks.6.4.ghost2.cheap_operation.1.num_batches_tracked\nblocks.7.0.ghost1.primary_conv.0.weight\nblocks.7.0.ghost1.primary_conv.1.weight\nblocks.7.0.ghost1.primary_conv.1.bias\nblocks.7.0.ghost1.primary_conv.1.running_mean\nblocks.7.0.ghost1.primary_conv.1.running_var\nblocks.7.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.7.0.ghost1.cheap_operation.0.weight\nblocks.7.0.ghost1.cheap_operation.1.weight\nblocks.7.0.ghost1.cheap_operation.1.bias\nblocks.7.0.ghost1.cheap_operation.1.running_mean\nblocks.7.0.ghost1.cheap_operation.1.running_var\nblocks.7.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.7.0.conv_dw.weight\nblocks.7.0.bn_dw.weight\nblocks.7.0.bn_dw.bias\nblocks.7.0.bn_dw.running_mean\nblocks.7.0.bn_dw.running_var\nblocks.7.0.bn_dw.num_batches_tracked\nblocks.7.0.se.conv_reduce.weight\nblocks.7.0.se.conv_reduce.bias\nblocks.7.0.se.conv_expand.weight\nblocks.7.0.se.conv_expand.bias\nblocks.7.0.ghost2.primary_conv.0.weight\nblocks.7.0.ghost2.primary_conv.1.weight\nblocks.7.0.ghost2.primary_conv.1.bias\nblocks.7.0.ghost2.primary_conv.1.running_mean\nblocks.7.0.ghost2.primary_conv.1.running_var\nblocks.7.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.7.0.ghost2.cheap_operation.0.weight\nblocks.7.0.ghost2.cheap_operation.1.weight\nblocks.7.0.ghost2.cheap_operation.1.bias\nblocks.7.0.ghost2.cheap_operation.1.running_mean\nblocks.7.0.ghost2.cheap_operation.1.running_var\nblocks.7.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.7.0.shortcut.0.weight\nblocks.7.0.shortcut.1.weight\nblocks.7.0.shortcut.1.bias\nblocks.7.0.shortcut.1.running_mean\nblocks.7.0.shortcut.1.running_var\nblocks.7.0.shortcut.1.num_batches_tracked\nblocks.7.0.shortcut.2.weight\nblocks.7.0.shortcut.3.weight\nblocks.7.0.shortcut.3.bias\nblocks.7.0.shortcut.3.running_mean\nblocks.7.0.shortcut.3.running_var\nblocks.7.0.shortcut.3.num_batches_tracked\nblocks.8.0.ghost1.primary_conv.0.weight\nblocks.8.0.ghost1.primary_conv.1.weight\nblocks.8.0.ghost1.primary_conv.1.bias\nblocks.8.0.ghost1.primary_conv.1.running_mean\nblocks.8.0.ghost1.primary_conv.1.running_var\nblocks.8.0.ghost1.primary_conv.1.num_batches_tracked\nblocks.8.0.ghost1.cheap_operation.0.weight\nblocks.8.0.ghost1.cheap_operation.1.weight\nblocks.8.0.ghost1.cheap_operation.1.bias\nblocks.8.0.ghost1.cheap_operation.1.running_mean\nblocks.8.0.ghost1.cheap_operation.1.running_var\nblocks.8.0.ghost1.cheap_operation.1.num_batches_tracked\nblocks.8.0.ghost2.primary_conv.0.weight\nblocks.8.0.ghost2.primary_conv.1.weight\nblocks.8.0.ghost2.primary_conv.1.bias\nblocks.8.0.ghost2.primary_conv.1.running_mean\nblocks.8.0.ghost2.primary_conv.1.running_var\nblocks.8.0.ghost2.primary_conv.1.num_batches_tracked\nblocks.8.0.ghost2.cheap_operation.0.weight\nblocks.8.0.ghost2.cheap_operation.1.weight\nblocks.8.0.ghost2.cheap_operation.1.bias\nblocks.8.0.ghost2.cheap_operation.1.running_mean\nblocks.8.0.ghost2.cheap_operation.1.running_var\nblocks.8.0.ghost2.cheap_operation.1.num_batches_tracked\nblocks.8.1.ghost1.primary_conv.0.weight\nblocks.8.1.ghost1.primary_conv.1.weight\nblocks.8.1.ghost1.primary_conv.1.bias\nblocks.8.1.ghost1.primary_conv.1.running_mean\nblocks.8.1.ghost1.primary_conv.1.running_var\nblocks.8.1.ghost1.primary_conv.1.num_batches_tracked\nblocks.8.1.ghost1.cheap_operation.0.weight\nblocks.8.1.ghost1.cheap_operation.1.weight\nblocks.8.1.ghost1.cheap_operation.1.bias\nblocks.8.1.ghost1.cheap_operation.1.running_mean\nblocks.8.1.ghost1.cheap_operation.1.running_var\nblocks.8.1.ghost1.cheap_operation.1.num_batches_tracked\nblocks.8.1.se.conv_reduce.weight\nblocks.8.1.se.conv_reduce.bias\nblocks.8.1.se.conv_expand.weight\nblocks.8.1.se.conv_expand.bias\nblocks.8.1.ghost2.primary_conv.0.weight\nblocks.8.1.ghost2.primary_conv.1.weight\nblocks.8.1.ghost2.primary_conv.1.bias\nblocks.8.1.ghost2.primary_conv.1.running_mean\nblocks.8.1.ghost2.primary_conv.1.running_var\nblocks.8.1.ghost2.primary_conv.1.num_batches_tracked\nblocks.8.1.ghost2.cheap_operation.0.weight\nblocks.8.1.ghost2.cheap_operation.1.weight\nblocks.8.1.ghost2.cheap_operation.1.bias\nblocks.8.1.ghost2.cheap_operation.1.running_mean\nblocks.8.1.ghost2.cheap_operation.1.running_var\nblocks.8.1.ghost2.cheap_operation.1.num_batches_tracked\nblocks.8.2.ghost1.primary_conv.0.weight\nblocks.8.2.ghost1.primary_conv.1.weight\nblocks.8.2.ghost1.primary_conv.1.bias\nblocks.8.2.ghost1.primary_conv.1.running_mean\nblocks.8.2.ghost1.primary_conv.1.running_var\nblocks.8.2.ghost1.primary_conv.1.num_batches_tracked\nblocks.8.2.ghost1.cheap_operation.0.weight\nblocks.8.2.ghost1.cheap_operation.1.weight\nblocks.8.2.ghost1.cheap_operation.1.bias\nblocks.8.2.ghost1.cheap_operation.1.running_mean\nblocks.8.2.ghost1.cheap_operation.1.running_var\nblocks.8.2.ghost1.cheap_operation.1.num_batches_tracked\nblocks.8.2.ghost2.primary_conv.0.weight\nblocks.8.2.ghost2.primary_conv.1.weight\nblocks.8.2.ghost2.primary_conv.1.bias\nblocks.8.2.ghost2.primary_conv.1.running_mean\nblocks.8.2.ghost2.primary_conv.1.running_var\nblocks.8.2.ghost2.primary_conv.1.num_batches_tracked\nblocks.8.2.ghost2.cheap_operation.0.weight\nblocks.8.2.ghost2.cheap_operation.1.weight\nblocks.8.2.ghost2.cheap_operation.1.bias\nblocks.8.2.ghost2.cheap_operation.1.running_mean\nblocks.8.2.ghost2.cheap_operation.1.running_var\nblocks.8.2.ghost2.cheap_operation.1.num_batches_tracked\nblocks.8.3.ghost1.primary_conv.0.weight\nblocks.8.3.ghost1.primary_conv.1.weight\nblocks.8.3.ghost1.primary_conv.1.bias\nblocks.8.3.ghost1.primary_conv.1.running_mean\nblocks.8.3.ghost1.primary_conv.1.running_var\nblocks.8.3.ghost1.primary_conv.1.num_batches_tracked\nblocks.8.3.ghost1.cheap_operation.0.weight\nblocks.8.3.ghost1.cheap_operation.1.weight\nblocks.8.3.ghost1.cheap_operation.1.bias\nblocks.8.3.ghost1.cheap_operation.1.running_mean\nblocks.8.3.ghost1.cheap_operation.1.running_var\nblocks.8.3.ghost1.cheap_operation.1.num_batches_tracked\nblocks.8.3.se.conv_reduce.weight\nblocks.8.3.se.conv_reduce.bias\nblocks.8.3.se.conv_expand.weight\nblocks.8.3.se.conv_expand.bias\nblocks.8.3.ghost2.primary_conv.0.weight\nblocks.8.3.ghost2.primary_conv.1.weight\nblocks.8.3.ghost2.primary_conv.1.bias\nblocks.8.3.ghost2.primary_conv.1.running_mean\nblocks.8.3.ghost2.primary_conv.1.running_var\nblocks.8.3.ghost2.primary_conv.1.num_batches_tracked\nblocks.8.3.ghost2.cheap_operation.0.weight\nblocks.8.3.ghost2.cheap_operation.1.weight\nblocks.8.3.ghost2.cheap_operation.1.bias\nblocks.8.3.ghost2.cheap_operation.1.running_mean\nblocks.8.3.ghost2.cheap_operation.1.running_var\nblocks.8.3.ghost2.cheap_operation.1.num_batches_tracked\nblocks.9.0.conv.weight\nblocks.9.0.bn1.weight\nblocks.9.0.bn1.bias\nblocks.9.0.bn1.running_mean\nblocks.9.0.bn1.running_var\nblocks.9.0.bn1.num_batches_tracked\n"
    }
   ],
   "source": [
    "ck = torch.load(\"../checkpoint_imagenet/state_dict_93.98.pth\")\n",
    "a = list(ck.keys())\n",
    "a1 = list(filter(lambda i: \"block\" in i ,a))\n",
    "for c, i in enumerate(a):\n",
    "    print(i)\n",
    "    if c>=507:\n",
    "        break\n",
    " \n",
    "# print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Feature after ghotnet block:  torch.Size([1, 960, 4, 4])\nFeature after global pool:  torch.Size([1, 960, 1, 1])\nFeature after conv_head:  torch.Size([1, 1280, 1, 1])\nTime inference one input: 0.038233280181884766\ntorch.Size([1, 1000])\nOut1 shape: torch.Size([1, 64, 28, 28])\nX1 shape: torch.Size([1, 16, 1, 1])\nX2 shape: torch.Size([1, 32, 1, 1])\nX3 shape: torch.Size([1, 128, 1, 1])\nTime:  0.03032398223876953\n"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = ghostnet(width=1)\n",
    "model.eval()\n",
    "# print(model)\n",
    "input = torch.randn(1,3,112,112)\n",
    "\n",
    "t1 = time.time()\n",
    "y = model(input)\n",
    "print(\"Time inference one input:\", time.time()-t1)\n",
    "print(y.size())\n",
    "\n",
    "input = torch.randn(1, 3, 112, 112)\n",
    "plfd_backbone = PFLDInference()\n",
    "plfd_backbone.eval()\n",
    "t1 = time.time()\n",
    "features, landmarks = plfd_backbone(input)\n",
    "print(\"Time: \", time.time()-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual\n",
    "w=64\n",
    "h=64\n",
    "stride=2\n",
    "expand_ratio=1\n",
    "res = InvertedResidual(w, h, stride, False, expand_ratio=6)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GhostModule(\n  (primary_conv): Sequential(\n    (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n  (cheap_operation): Sequential(\n    (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Ghost\n",
    "input_channel=64\n",
    "output_channel=64\n",
    "k=2\n",
    "s=2\n",
    "se_ratio=2\n",
    "gho = GhostModule(input_channel, output_channel, kernel_size=1, ratio=2, dw_size=3, stride=2, relu=True)\n",
    "gho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "ghobotto = GhostBottleneck(64, 64, 64, dw_kernel_size=3,\n",
    "                 stride=1, act_layer=nn.ReLU, se_ratio=0.)\n",
    "ghobotto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "9\n"
    }
   ],
   "source": [
    " cfgs = [\n",
    "        # k, t, c, SE, s \n",
    "        # stage1\n",
    "        [[3,  16,  16, 0, 1]],\n",
    "        # stage2\n",
    "        [[3,  48,  24, 0, 2]],\n",
    "        [[3,  72,  24, 0, 1]],\n",
    "        # stage3\n",
    "        [[5,  72,  40, 0.25, 2]],\n",
    "        [[5, 120,  40, 0.25, 1]],\n",
    "        # stage4\n",
    "        [[3, 240,  80, 0, 2]],\n",
    "        [[3, 200,  80, 0, 1],\n",
    "         [3, 184,  80, 0, 1],\n",
    "         [3, 184,  80, 0, 1],\n",
    "         [3, 480, 112, 0.25, 1],\n",
    "         [3, 672, 112, 0.25, 1]\n",
    "        ],\n",
    "        # stage5\n",
    "        [[5, 672, 160, 0.25, 2]],\n",
    "        [[5, 960, 160, 0, 1],\n",
    "         [5, 960, 160, 0.25, 1],\n",
    "         [5, 960, 160, 0, 1],\n",
    "         [5, 960, 160, 0.25, 1]\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "print(len(cfgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37064bitentranceconda9b4673bfa1754abd8ca93decff70e970",
   "display_name": "Python 3.7.0 64-bit ('entrance': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}