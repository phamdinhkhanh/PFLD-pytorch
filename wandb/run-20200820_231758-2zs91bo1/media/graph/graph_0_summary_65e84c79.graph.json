{"format": "torch", "nodes": [{"name": "conv_stem", "id": 140184479530512, "class_name": "Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)", "parameters": [["weight", [16, 3, 3, 3]]], "output_shape": [[64, 16, 56, 56]], "num_parameters": [432]}, {"name": "bn1", "id": 140185146976800, "class_name": "BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [16]], ["bias", [16]]], "output_shape": [[64, 16, 56, 56]], "num_parameters": [16, 16]}, {"name": "act1", "id": 140186874397136, "class_name": "ReLU(inplace=True)", "parameters": [], "output_shape": [[64, 16, 56, 56]], "num_parameters": []}, {"name": "begining_blocks.0.0", "id": 140187015315640, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n  (bn_dw): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["ghost1.primary_conv.0.weight", [8, 16, 1, 1]], ["ghost1.primary_conv.1.weight", [8]], ["ghost1.primary_conv.1.bias", [8]], ["ghost1.cheap_operation.0.weight", [8, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [8]], ["ghost1.cheap_operation.1.bias", [8]], ["conv_dw.weight", [16, 1, 3, 3]], ["bn_dw.weight", [16]], ["bn_dw.bias", [16]], ["ghost2.primary_conv.0.weight", [8, 16, 1, 1]], ["ghost2.primary_conv.1.weight", [8]], ["ghost2.primary_conv.1.bias", [8]], ["ghost2.cheap_operation.0.weight", [8, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [8]], ["ghost2.cheap_operation.1.bias", [8]], ["shortcut.0.weight", [16, 1, 3, 3]], ["shortcut.1.weight", [16]], ["shortcut.1.bias", [16]], ["shortcut.2.weight", [16, 16, 1, 1]], ["shortcut.3.weight", [16]], ["shortcut.3.bias", [16]]], "output_shape": [[64, 16, 28, 28]], "num_parameters": [128, 8, 8, 72, 8, 8, 144, 16, 16, 128, 8, 8, 72, 8, 8, 144, 16, 16, 256, 16, 16]}, {"name": "begining_blocks.1.0", "id": 140184479529504, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential(\n    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["ghost1.primary_conv.0.weight", [24, 16, 1, 1]], ["ghost1.primary_conv.1.weight", [24]], ["ghost1.primary_conv.1.bias", [24]], ["ghost1.cheap_operation.0.weight", [24, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [24]], ["ghost1.cheap_operation.1.bias", [24]], ["ghost2.primary_conv.0.weight", [12, 48, 1, 1]], ["ghost2.primary_conv.1.weight", [12]], ["ghost2.primary_conv.1.bias", [12]], ["ghost2.cheap_operation.0.weight", [12, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [12]], ["ghost2.cheap_operation.1.bias", [12]], ["shortcut.0.weight", [16, 1, 3, 3]], ["shortcut.1.weight", [16]], ["shortcut.1.bias", [16]], ["shortcut.2.weight", [24, 16, 1, 1]], ["shortcut.3.weight", [24]], ["shortcut.3.bias", [24]]], "output_shape": [[64, 24, 28, 28]], "num_parameters": [384, 24, 24, 216, 24, 24, 576, 12, 12, 108, 12, 12, 144, 16, 16, 384, 24, 24]}, {"name": "begining_blocks.2.0", "id": 140184479662656, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(24, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)\n      (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(72, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(12, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n      (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [36, 24, 1, 1]], ["ghost1.primary_conv.1.weight", [36]], ["ghost1.primary_conv.1.bias", [36]], ["ghost1.cheap_operation.0.weight", [36, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [36]], ["ghost1.cheap_operation.1.bias", [36]], ["ghost2.primary_conv.0.weight", [12, 72, 1, 1]], ["ghost2.primary_conv.1.weight", [12]], ["ghost2.primary_conv.1.bias", [12]], ["ghost2.cheap_operation.0.weight", [12, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [12]], ["ghost2.cheap_operation.1.bias", [12]]], "output_shape": [[64, 24, 28, 28]], "num_parameters": [864, 36, 36, 324, 36, 36, 864, 12, 12, 108, 12, 12]}, {"name": "begining_blocks.3.0", "id": 140184479666072, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(24, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(36, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=36, bias=False)\n      (1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (se): SqueezeExcite(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (conv_reduce): Conv2d(72, 20, kernel_size=(1, 1), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (conv_expand): Conv2d(20, 72, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(72, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential(\n    (0): Conv2d(24, 24, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=24, bias=False)\n    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(24, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["ghost1.primary_conv.0.weight", [36, 24, 1, 1]], ["ghost1.primary_conv.1.weight", [36]], ["ghost1.primary_conv.1.bias", [36]], ["ghost1.cheap_operation.0.weight", [36, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [36]], ["ghost1.cheap_operation.1.bias", [36]], ["se.conv_reduce.weight", [20, 72, 1, 1]], ["se.conv_reduce.bias", [20]], ["se.conv_expand.weight", [72, 20, 1, 1]], ["se.conv_expand.bias", [72]], ["ghost2.primary_conv.0.weight", [20, 72, 1, 1]], ["ghost2.primary_conv.1.weight", [20]], ["ghost2.primary_conv.1.bias", [20]], ["ghost2.cheap_operation.0.weight", [20, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [20]], ["ghost2.cheap_operation.1.bias", [20]], ["shortcut.0.weight", [24, 1, 5, 5]], ["shortcut.1.weight", [24]], ["shortcut.1.bias", [24]], ["shortcut.2.weight", [40, 24, 1, 1]], ["shortcut.3.weight", [40]], ["shortcut.3.bias", [40]]], "output_shape": [[64, 40, 28, 28]], "num_parameters": [864, 36, 36, 324, 36, 36, 1440, 20, 1440, 72, 1440, 20, 20, 180, 20, 20, 600, 24, 24, 960, 40, 40]}, {"name": "begining_blocks.4.0", "id": 140184463874592, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(40, 60, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(60, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=60, bias=False)\n      (1): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (se): SqueezeExcite(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (conv_reduce): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (conv_expand): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(120, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=20, bias=False)\n      (1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [60, 40, 1, 1]], ["ghost1.primary_conv.1.weight", [60]], ["ghost1.primary_conv.1.bias", [60]], ["ghost1.cheap_operation.0.weight", [60, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [60]], ["ghost1.cheap_operation.1.bias", [60]], ["se.conv_reduce.weight", [32, 120, 1, 1]], ["se.conv_reduce.bias", [32]], ["se.conv_expand.weight", [120, 32, 1, 1]], ["se.conv_expand.bias", [120]], ["ghost2.primary_conv.0.weight", [20, 120, 1, 1]], ["ghost2.primary_conv.1.weight", [20]], ["ghost2.primary_conv.1.bias", [20]], ["ghost2.cheap_operation.0.weight", [20, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [20]], ["ghost2.cheap_operation.1.bias", [20]]], "output_shape": [[64, 40, 28, 28]], "num_parameters": [2400, 60, 60, 540, 60, 60, 3840, 32, 3840, 120, 2400, 20, 20, 180, 20, 20]}, {"name": "begining_blocks.5.0", "id": 140184464024296, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)\n      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential(\n    (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n    (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(40, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["ghost1.primary_conv.0.weight", [120, 40, 1, 1]], ["ghost1.primary_conv.1.weight", [120]], ["ghost1.primary_conv.1.bias", [120]], ["ghost1.cheap_operation.0.weight", [120, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [120]], ["ghost1.cheap_operation.1.bias", [120]], ["ghost2.primary_conv.0.weight", [40, 240, 1, 1]], ["ghost2.primary_conv.1.weight", [40]], ["ghost2.primary_conv.1.bias", [40]], ["ghost2.cheap_operation.0.weight", [40, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [40]], ["ghost2.cheap_operation.1.bias", [40]], ["shortcut.0.weight", [40, 1, 3, 3]], ["shortcut.1.weight", [40]], ["shortcut.1.bias", [40]], ["shortcut.2.weight", [80, 40, 1, 1]], ["shortcut.3.weight", [80]], ["shortcut.3.bias", [80]]], "output_shape": [[64, 80, 28, 28]], "num_parameters": [4800, 120, 120, 1080, 120, 120, 9600, 40, 40, 360, 40, 40, 360, 40, 40, 3200, 80, 80]}, {"name": "remaining_blocks.0.0", "id": 140184464026648, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(80, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(100, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=100, bias=False)\n      (1): BatchNorm2d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (conv_dw): Conv2d(200, 200, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=200, bias=False)\n  (bn_dw): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(200, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential(\n    (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=80, bias=False)\n    (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (3): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["ghost1.primary_conv.0.weight", [100, 80, 1, 1]], ["ghost1.primary_conv.1.weight", [100]], ["ghost1.primary_conv.1.bias", [100]], ["ghost1.cheap_operation.0.weight", [100, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [100]], ["ghost1.cheap_operation.1.bias", [100]], ["conv_dw.weight", [200, 1, 3, 3]], ["bn_dw.weight", [200]], ["bn_dw.bias", [200]], ["ghost2.primary_conv.0.weight", [40, 200, 1, 1]], ["ghost2.primary_conv.1.weight", [40]], ["ghost2.primary_conv.1.bias", [40]], ["ghost2.cheap_operation.0.weight", [40, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [40]], ["ghost2.cheap_operation.1.bias", [40]], ["shortcut.0.weight", [80, 1, 3, 3]], ["shortcut.1.weight", [80]], ["shortcut.1.bias", [80]], ["shortcut.2.weight", [80, 80, 1, 1]], ["shortcut.3.weight", [80]], ["shortcut.3.bias", [80]]], "output_shape": [[64, 80, 14, 14]], "num_parameters": [8000, 100, 100, 900, 100, 100, 1800, 200, 200, 8000, 40, 40, 360, 40, 40, 720, 80, 80, 6400, 80, 80]}, {"name": "remaining_blocks.0.1", "id": 140184463635624, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(80, 92, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(92, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=92, bias=False)\n      (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(184, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [92, 80, 1, 1]], ["ghost1.primary_conv.1.weight", [92]], ["ghost1.primary_conv.1.bias", [92]], ["ghost1.cheap_operation.0.weight", [92, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [92]], ["ghost1.cheap_operation.1.bias", [92]], ["ghost2.primary_conv.0.weight", [40, 184, 1, 1]], ["ghost2.primary_conv.1.weight", [40]], ["ghost2.primary_conv.1.bias", [40]], ["ghost2.cheap_operation.0.weight", [40, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [40]], ["ghost2.cheap_operation.1.bias", [40]]], "output_shape": [[64, 80, 14, 14]], "num_parameters": [7360, 92, 92, 828, 92, 92, 7360, 40, 40, 360, 40, 40]}, {"name": "remaining_blocks.0.2", "id": 140184463637640, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(80, 92, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(92, 92, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=92, bias=False)\n      (1): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(184, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=40, bias=False)\n      (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [92, 80, 1, 1]], ["ghost1.primary_conv.1.weight", [92]], ["ghost1.primary_conv.1.bias", [92]], ["ghost1.cheap_operation.0.weight", [92, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [92]], ["ghost1.cheap_operation.1.bias", [92]], ["ghost2.primary_conv.0.weight", [40, 184, 1, 1]], ["ghost2.primary_conv.1.weight", [40]], ["ghost2.primary_conv.1.bias", [40]], ["ghost2.cheap_operation.0.weight", [40, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [40]], ["ghost2.cheap_operation.1.bias", [40]]], "output_shape": [[64, 80, 14, 14]], "num_parameters": [7360, 92, 92, 828, 92, 92, 7360, 40, 40, 360, 40, 40]}, {"name": "remaining_blocks.0.3", "id": 140184463770568, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)\n      (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (se): SqueezeExcite(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (conv_reduce): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (conv_expand): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(480, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)\n      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential(\n    (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n    (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(80, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (3): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["ghost1.primary_conv.0.weight", [240, 80, 1, 1]], ["ghost1.primary_conv.1.weight", [240]], ["ghost1.primary_conv.1.bias", [240]], ["ghost1.cheap_operation.0.weight", [240, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [240]], ["ghost1.cheap_operation.1.bias", [240]], ["se.conv_reduce.weight", [120, 480, 1, 1]], ["se.conv_reduce.bias", [120]], ["se.conv_expand.weight", [480, 120, 1, 1]], ["se.conv_expand.bias", [480]], ["ghost2.primary_conv.0.weight", [56, 480, 1, 1]], ["ghost2.primary_conv.1.weight", [56]], ["ghost2.primary_conv.1.bias", [56]], ["ghost2.cheap_operation.0.weight", [56, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [56]], ["ghost2.cheap_operation.1.bias", [56]], ["shortcut.0.weight", [80, 1, 3, 3]], ["shortcut.1.weight", [80]], ["shortcut.1.bias", [80]], ["shortcut.2.weight", [112, 80, 1, 1]], ["shortcut.3.weight", [112]], ["shortcut.3.bias", [112]]], "output_shape": [[64, 112, 14, 14]], "num_parameters": [19200, 240, 240, 2160, 240, 240, 57600, 120, 57600, 480, 26880, 56, 56, 504, 56, 56, 720, 80, 80, 8960, 112, 112]}, {"name": "remaining_blocks.0.4", "id": 140184463772864, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(112, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n      (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (se): SqueezeExcite(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(672, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(56, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=56, bias=False)\n      (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [336, 112, 1, 1]], ["ghost1.primary_conv.1.weight", [336]], ["ghost1.primary_conv.1.bias", [336]], ["ghost1.cheap_operation.0.weight", [336, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [336]], ["ghost1.cheap_operation.1.bias", [336]], ["se.conv_reduce.weight", [168, 672, 1, 1]], ["se.conv_reduce.bias", [168]], ["se.conv_expand.weight", [672, 168, 1, 1]], ["se.conv_expand.bias", [672]], ["ghost2.primary_conv.0.weight", [56, 672, 1, 1]], ["ghost2.primary_conv.1.weight", [56]], ["ghost2.primary_conv.1.bias", [56]], ["ghost2.cheap_operation.0.weight", [56, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [56]], ["ghost2.cheap_operation.1.bias", [56]]], "output_shape": [[64, 112, 14, 14]], "num_parameters": [37632, 336, 336, 3024, 336, 336, 112896, 168, 112896, 672, 37632, 56, 56, 504, 56, 56]}, {"name": "remaining_blocks.1.0", "id": 140184463398728, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(112, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n      (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (se): SqueezeExcite(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (conv_reduce): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (conv_expand): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential(\n    (0): Conv2d(112, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=112, bias=False)\n    (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(112, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n)", "parameters": [["ghost1.primary_conv.0.weight", [336, 112, 1, 1]], ["ghost1.primary_conv.1.weight", [336]], ["ghost1.primary_conv.1.bias", [336]], ["ghost1.cheap_operation.0.weight", [336, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [336]], ["ghost1.cheap_operation.1.bias", [336]], ["se.conv_reduce.weight", [168, 672, 1, 1]], ["se.conv_reduce.bias", [168]], ["se.conv_expand.weight", [672, 168, 1, 1]], ["se.conv_expand.bias", [672]], ["ghost2.primary_conv.0.weight", [80, 672, 1, 1]], ["ghost2.primary_conv.1.weight", [80]], ["ghost2.primary_conv.1.bias", [80]], ["ghost2.cheap_operation.0.weight", [80, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [80]], ["ghost2.cheap_operation.1.bias", [80]], ["shortcut.0.weight", [112, 1, 5, 5]], ["shortcut.1.weight", [112]], ["shortcut.1.bias", [112]], ["shortcut.2.weight", [160, 112, 1, 1]], ["shortcut.3.weight", [160]], ["shortcut.3.bias", [160]]], "output_shape": [[64, 160, 14, 14]], "num_parameters": [37632, 336, 336, 3024, 336, 336, 112896, 168, 112896, 672, 53760, 80, 80, 720, 80, 80, 2800, 112, 112, 17920, 160, 160]}, {"name": "remaining_blocks.2.0", "id": 140184463532496, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [480, 160, 1, 1]], ["ghost1.primary_conv.1.weight", [480]], ["ghost1.primary_conv.1.bias", [480]], ["ghost1.cheap_operation.0.weight", [480, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [480]], ["ghost1.cheap_operation.1.bias", [480]], ["ghost2.primary_conv.0.weight", [80, 960, 1, 1]], ["ghost2.primary_conv.1.weight", [80]], ["ghost2.primary_conv.1.bias", [80]], ["ghost2.cheap_operation.0.weight", [80, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [80]], ["ghost2.cheap_operation.1.bias", [80]]], "output_shape": [[64, 160, 14, 14]], "num_parameters": [76800, 480, 480, 4320, 480, 480, 76800, 80, 80, 720, 80, 80]}, {"name": "remaining_blocks.2.1", "id": 140184463534288, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (se): SqueezeExcite(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [480, 160, 1, 1]], ["ghost1.primary_conv.1.weight", [480]], ["ghost1.primary_conv.1.bias", [480]], ["ghost1.cheap_operation.0.weight", [480, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [480]], ["ghost1.cheap_operation.1.bias", [480]], ["se.conv_reduce.weight", [240, 960, 1, 1]], ["se.conv_reduce.bias", [240]], ["se.conv_expand.weight", [960, 240, 1, 1]], ["se.conv_expand.bias", [960]], ["ghost2.primary_conv.0.weight", [80, 960, 1, 1]], ["ghost2.primary_conv.1.weight", [80]], ["ghost2.primary_conv.1.bias", [80]], ["ghost2.cheap_operation.0.weight", [80, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [80]], ["ghost2.cheap_operation.1.bias", [80]]], "output_shape": [[64, 160, 14, 14]], "num_parameters": [76800, 480, 480, 4320, 480, 480, 230400, 240, 230400, 960, 76800, 80, 80, 720, 80, 80]}, {"name": "remaining_blocks.2.2", "id": 140184463151400, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [480, 160, 1, 1]], ["ghost1.primary_conv.1.weight", [480]], ["ghost1.primary_conv.1.bias", [480]], ["ghost1.cheap_operation.0.weight", [480, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [480]], ["ghost1.cheap_operation.1.bias", [480]], ["ghost2.primary_conv.0.weight", [80, 960, 1, 1]], ["ghost2.primary_conv.1.weight", [80]], ["ghost2.primary_conv.1.bias", [80]], ["ghost2.cheap_operation.0.weight", [80, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [80]], ["ghost2.cheap_operation.1.bias", [80]]], "output_shape": [[64, 160, 14, 14]], "num_parameters": [76800, 480, 480, 4320, 480, 480, 76800, 80, 80, 720, 80, 80]}, {"name": "remaining_blocks.2.3", "id": 140184463153192, "class_name": "GhostBottleneck(\n  (ghost1): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(160, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n      (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n    )\n  )\n  (se): SqueezeExcite(\n    (avg_pool): AdaptiveAvgPool2d(output_size=1)\n    (conv_reduce): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n    (act1): ReLU(inplace=True)\n    (conv_expand): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n  )\n  (ghost2): GhostModule(\n    (primary_conv): Sequential(\n      (0): Conv2d(960, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n    (cheap_operation): Sequential(\n      (0): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n      (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sequential()\n    )\n  )\n  (shortcut): Sequential()\n)", "parameters": [["ghost1.primary_conv.0.weight", [480, 160, 1, 1]], ["ghost1.primary_conv.1.weight", [480]], ["ghost1.primary_conv.1.bias", [480]], ["ghost1.cheap_operation.0.weight", [480, 1, 3, 3]], ["ghost1.cheap_operation.1.weight", [480]], ["ghost1.cheap_operation.1.bias", [480]], ["se.conv_reduce.weight", [240, 960, 1, 1]], ["se.conv_reduce.bias", [240]], ["se.conv_expand.weight", [960, 240, 1, 1]], ["se.conv_expand.bias", [960]], ["ghost2.primary_conv.0.weight", [80, 960, 1, 1]], ["ghost2.primary_conv.1.weight", [80]], ["ghost2.primary_conv.1.bias", [80]], ["ghost2.cheap_operation.0.weight", [80, 1, 3, 3]], ["ghost2.cheap_operation.1.weight", [80]], ["ghost2.cheap_operation.1.bias", [80]]], "output_shape": [[64, 160, 14, 14]], "num_parameters": [76800, 480, 480, 4320, 480, 480, 230400, 240, 230400, 960, 76800, 80, 80, 720, 80, 80]}, {"name": "remaining_blocks.3.0", "id": 140186873923624, "class_name": "ConvBnAct(\n  (conv): Conv2d(160, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): ReLU(inplace=True)\n)", "parameters": [["conv.weight", [16, 160, 1, 1]], ["bn1.weight", [16]], ["bn1.bias", [16]]], "output_shape": [[64, 16, 14, 14]], "num_parameters": [2560, 16, 16]}, {"name": "avg_pool1", "id": 140184463296328, "class_name": "AvgPool2d(kernel_size=14, stride=14, padding=0)", "parameters": [], "output_shape": [[64, 16, 1, 1]], "num_parameters": []}, {"name": "conv7.0", "id": 140184463295824, "class_name": "Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)", "parameters": [["weight", [32, 16, 3, 3]]], "output_shape": [[64, 32, 7, 7]], "num_parameters": [4608]}, {"name": "conv7.1", "id": 140184463295880, "class_name": "BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)", "parameters": [["weight", [32]], ["bias", [32]]], "output_shape": [[64, 32, 7, 7]], "num_parameters": [32, 32]}, {"name": "conv7.2", "id": 140184463295936, "class_name": "ReLU(inplace=True)", "parameters": [], "output_shape": [[64, 32, 7, 7]], "num_parameters": []}, {"name": "avg_pool2", "id": 140184463296384, "class_name": "AvgPool2d(kernel_size=7, stride=7, padding=0)", "parameters": [], "output_shape": [[64, 32, 1, 1]], "num_parameters": []}, {"name": "conv8", "id": 140184463296048, "class_name": "Conv2d(32, 128, kernel_size=(7, 7), stride=(1, 1))", "parameters": [["weight", [128, 32, 7, 7]], ["bias", [128]]], "output_shape": [[64, 128, 1, 1]], "num_parameters": [200704, 128]}, {"name": "relu", "id": 140184463295544, "class_name": "ReLU(inplace=True)", "parameters": [], "output_shape": [[64, 128, 1, 1]], "num_parameters": []}, {"name": "fc", "id": 140184463296440, "class_name": "Linear(in_features=176, out_features=196, bias=True)", "parameters": [["weight", [196, 176]], ["bias", [196]]], "output_shape": [[64, 196]], "num_parameters": [34496, 196]}], "edges": []}